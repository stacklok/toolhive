apiVersion: chainsaw.kyverno.io/v1alpha1
kind: Test
metadata:
  name: configmap-mode-mcp-server
spec:
  description: Tests TOOLHIVE_USE_CONFIGMAP=true environment variable functionality - verifies operator uses volume mounting instead of individual config flags
  timeouts:
    apply: 30s
    assert: 60s
    cleanup: 30s
    exec: 300s
  steps:
  - name: verify-operator
    description: Ensure operator is ready before testing
    try:
    - assert:
        file: ../../setup/assert-operator-ready.yaml

  - name: enable-configmap-mode
    description: Enable ConfigMap mode by setting environment variable on operator
    try:
    - script:
        content: |
          echo "Setting TOOLHIVE_USE_CONFIGMAP=true on operator deployment..."
          
          # Use strategic merge patch to add the environment variable to existing env array
          kubectl patch deployment toolhive-operator -n toolhive-system --type='strategic' -p='{"spec":{"template":{"spec":{"containers":[{"name":"manager","env":[{"name":"TOOLHIVE_USE_CONFIGMAP","value":"true"}]}]}}}}'
          
          # Wait for rollout to complete
          kubectl rollout status deployment/toolhive-operator -n toolhive-system --timeout=60s
          
          # Verify the environment variable was set
          echo "Verifying TOOLHIVE_USE_CONFIGMAP environment variable is set..."
          ENV_VAR=$(kubectl get deployment toolhive-operator -n toolhive-system -o jsonpath='{.spec.template.spec.containers[?(@.name=="manager")].env[?(@.name=="TOOLHIVE_USE_CONFIGMAP")].value}')
          if [ "$ENV_VAR" = "true" ]; then
            echo "✓ TOOLHIVE_USE_CONFIGMAP=true verified on operator deployment"
          else
            echo "✗ Failed to set TOOLHIVE_USE_CONFIGMAP environment variable"
            echo "Current environment variables:"
            kubectl get deployment toolhive-operator -n toolhive-system -o jsonpath='{.spec.template.spec.containers[?(@.name=="manager")].env[*]}' | jq '.'
            exit 1
          fi
      
  - name: deploy-test-secret
    description: Deploy test secret for MCPServer
    try:
    - apply:
        file: test-secret.yaml
    - assert:
        file: test-secret.yaml

  - name: deploy-mcpserver-configmap-mode
    description: Deploy MCPServer instance (will use ConfigMap mode due to env var)
    try:
    - apply:
        file: mcpserver.yaml
    - assert:
        file: mcpserver.yaml
    - assert:
        file: assert-mcpserver-running.yaml
    - assert:
        file: assert-mcpserver-pod-running.yaml
    - assert:
        file: assert-deployment-uses-volume-mounting.yaml
    - assert:
        file: assert-statefulset-serviceaccount.yaml

  - name: verify-configmap-functionality
    description: Verify ConfigMap is created with proper content and deployment works
    try:
    - script:
        content: |
          echo "Verifying ConfigMap mode functionality..."
          
          # Wait for ConfigMap to be created
          for i in $(seq 1 10); do
            if kubectl get configmap yardstick-runconfig -n toolhive-system >/dev/null 2>&1; then
              echo "✓ ConfigMap yardstick-runconfig exists"
              break
            fi
            echo "  Waiting for ConfigMap... (attempt $i/10)"
            sleep 2
          done
          
          # Verify ConfigMap contains runconfig.json content
          CONFIGMAP_JSON=$(kubectl get configmap yardstick-runconfig -n toolhive-system -o jsonpath='{.data.runconfig\.json}' 2>/dev/null || echo "")
          
          if [ -z "$CONFIGMAP_JSON" ]; then
            echo "✗ ConfigMap does not contain runconfig.json data"
            kubectl get configmap yardstick-runconfig -n toolhive-system -o yaml
            exit 1
          fi
          
          echo "✓ ConfigMap contains runconfig.json data"
          
          # Validate JSON structure
          if echo "$CONFIGMAP_JSON" | jq -e '.schema_version and .image and .name and .transport' > /dev/null 2>&1; then
            echo "✓ runconfig.json contains required fields"
          else
            echo "✗ runconfig.json missing required fields"
            exit 1
          fi

          # Validate environment variables are properly embedded in runconfig.json
          echo "Validating environment variables in ConfigMap..."
          if echo "$CONFIGMAP_JSON" | jq -e '.env_vars.TEST_ENV_VAR == "configmap_test_value"' > /dev/null 2>&1; then
            echo "✓ TEST_ENV_VAR environment variable found with correct value"
          else
            echo "✗ TEST_ENV_VAR environment variable missing or incorrect value"
            echo "Environment variables in ConfigMap: $(echo "$CONFIGMAP_JSON" | jq '.env_vars // {}')"
            exit 1
          fi

          if echo "$CONFIGMAP_JSON" | jq -e '.env_vars.ANOTHER_TEST_VAR == "file_based_env"' > /dev/null 2>&1; then
            echo "✓ ANOTHER_TEST_VAR environment variable found with correct value"
          else
            echo "✗ ANOTHER_TEST_VAR environment variable missing or incorrect value"
            exit 1
          fi

          echo "✓ Environment variables properly embedded in ConfigMap runconfig.json"
          
          # Verify deployment uses volume mounting for ConfigMap
          echo "Verifying deployment uses ConfigMap volume mounting..."
          DEPLOYMENT_ARGS=$(kubectl get deployment yardstick -n toolhive-system -o jsonpath='{.spec.template.spec.containers[0].args}')
          echo "Deployment args: $DEPLOYMENT_ARGS"

          # Verify ConfigMap volume is mounted
          echo "Verifying ConfigMap volume is mounted..."
          VOLUME_MOUNTS=$(kubectl get deployment yardstick -n toolhive-system -o jsonpath='{.spec.template.spec.containers[0].volumeMounts}')
          VOLUMES=$(kubectl get deployment yardstick -n toolhive-system -o jsonpath='{.spec.template.spec.volumes}')

          echo "Volume mounts: $VOLUME_MOUNTS"
          echo "Volumes: $VOLUMES"

          # Check for runconfig volume mount
          if echo "$VOLUME_MOUNTS" | jq -e '.[] | select(.name=="runconfig" and .mountPath=="/etc/runconfig" and .readOnly==true)' > /dev/null 2>&1; then
            echo "✓ runconfig volume mount found at /etc/runconfig"
          else
            echo "✗ runconfig volume mount not found or incorrect configuration"
            exit 1
          fi

          # Check for ConfigMap volume source
          if echo "$VOLUMES" | jq -e '.[] | select(.name=="runconfig" and .configMap.name=="yardstick-runconfig")' > /dev/null 2>&1; then
            echo "✓ ConfigMap volume source found referencing yardstick-runconfig"
          else
            echo "✗ ConfigMap volume source not found or incorrect configuration"
            exit 1
          fi

          if echo "$DEPLOYMENT_ARGS" | grep -q -- "--k8s-pod-patch="; then
            echo "✓ Deployment uses --k8s-pod-patch flag"
          else
            echo "✗ Deployment does not use --k8s-pod-patch flag"
            exit 1
          fi
          
          # Verify individual config flags are NOT present
          if echo "$DEPLOYMENT_ARGS" | grep -q -- "--transport=stdio"; then
            echo "✗ Deployment should not use --transport flag when using ConfigMap"
            exit 1
          fi
          
          if echo "$DEPLOYMENT_ARGS" | grep -q -- "--name=yardstick"; then
            echo "✗ Deployment should not use --name flag when using ConfigMap"
            exit 1
          fi
          
          echo "✓ Individual config flags correctly omitted"

          # Validate k8s-pod-patch contains secrets
          echo "Validating k8s-pod-patch contains secrets..."
          # Extract the JSON argument by finding the --k8s-pod-patch flag in the args array
          POD_PATCH_ARG=$(echo "$DEPLOYMENT_ARGS" | jq -r '.[] | select(startswith("--k8s-pod-patch=")) | sub("^--k8s-pod-patch="; "")')

          if [ -n "$POD_PATCH_ARG" ]; then
            echo "Pod patch argument found, validating contents..."
            echo "Pod patch JSON: $POD_PATCH_ARG"

            # Check if pod patch contains MCP container with env vars
            if echo "$POD_PATCH_ARG" | jq -e '.spec.containers[] | select(.name=="mcp") | .env[]' > /dev/null 2>&1; then
              echo "✓ Pod patch contains MCP container with environment variables"
            else
              echo "✗ Pod patch does not contain MCP container with environment variables"
              echo "Pod patch contents: $POD_PATCH_ARG"
              exit 1
            fi

            # Validate specific secret environment variables
            if echo "$POD_PATCH_ARG" | jq -e '.spec.containers[] | select(.name=="mcp") | .env[] | select(.name=="YARDSTICK_API_TOKEN")' > /dev/null 2>&1; then
              echo "✓ Pod patch contains YARDSTICK_API_TOKEN environment variable"
            else
              echo "✗ Pod patch missing YARDSTICK_API_TOKEN environment variable"
              exit 1
            fi

            if echo "$POD_PATCH_ARG" | jq -e '.spec.containers[] | select(.name=="mcp") | .env[] | select(.name=="GITHUB_TOKEN")' > /dev/null 2>&1; then
              echo "✓ Pod patch contains GITHUB_TOKEN environment variable"
            else
              echo "✗ Pod patch missing GITHUB_TOKEN environment variable"
              exit 1
            fi

            # Validate secretKeyRef structure
            if echo "$POD_PATCH_ARG" | jq -e '.spec.containers[] | select(.name=="mcp") | .env[] | select(.name=="YARDSTICK_API_TOKEN") | .valueFrom.secretKeyRef | select(.name=="yardstick-test-secret" and .key=="api-token")' > /dev/null 2>&1; then
              echo "✓ YARDSTICK_API_TOKEN has correct secretKeyRef structure"
            else
              echo "✗ YARDSTICK_API_TOKEN secretKeyRef structure is incorrect"
              exit 1
            fi

            # Validate serviceAccountName in pod patch
            if echo "$POD_PATCH_ARG" | jq -e '.spec.serviceAccountName == "yardstick-custom-sa"' > /dev/null 2>&1; then
              echo "✓ Pod patch contains correct serviceAccountName"
            else
              echo "✗ Pod patch missing or has incorrect serviceAccountName"
              echo "Expected: yardstick-custom-sa"
              echo "Actual: $(echo "$POD_PATCH_ARG" | jq -r '.spec.serviceAccountName // "not set"')"
              exit 1
            fi

          else
            echo "✗ No pod patch argument found"
            exit 1
          fi

          echo "✅ ConfigMap mode functionality with secrets and serviceAccount verified successfully!"

  - name: cleanup-configmap-mode
    description: Disable ConfigMap mode to avoid affecting subsequent tests
    try:
    - script:
        content: |
          echo "Disabling ConfigMap mode by removing environment variable..."
          
          # Use JSON patch to remove the specific environment variable
          kubectl patch deployment toolhive-operator -n toolhive-system --type='json' -p='[{"op": "remove", "path": "/spec/template/spec/containers/0/env", "value": {"name": "TOOLHIVE_USE_CONFIGMAP"}}]' || echo "Environment variable may not exist to remove"
          
          # Alternative: set it to false instead of removing
          kubectl patch deployment toolhive-operator -n toolhive-system --type='strategic' -p='{"spec":{"template":{"spec":{"containers":[{"name":"manager","env":[{"name":"TOOLHIVE_USE_CONFIGMAP","value":"false"}]}]}}}}'
          
          # Wait for rollout to complete
          kubectl rollout status deployment/toolhive-operator -n toolhive-system --timeout=60s
          
          echo "✓ ConfigMap mode cleanup completed"